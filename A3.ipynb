{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 9. Effectiveness of word2vec\n",
    "\n",
    "We now repeat everything done in the file A3_one_hot using word2vec embeddings in place of one-hot embeddings. This will require re-running steps 1-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from random import random\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import math as math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "\n",
    "For this assignment, you must download the data and extract it into `data/`. The dataset contains two files, both containing a single caption on each line. We should have 415,795 sentences in the training captions and 500 sentences in the validation captions.\n",
    "\n",
    "To download the data, run the following directly on your server: `wget https://s3-us-west-2.amazonaws.com/cpsc532l-data/a3_data.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data into memory.\n",
    "train_sentences = [line.strip() for line in open(\"data/mscoco_train_captions.txt\").readlines()]\n",
    "val_sentences = [line.strip() for line in open(\"data/mscoco_val_captions.txt\").readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "The code provided below creates word embeddings for you to use. After creating the vocabulary, we construct both one-hot embeddings and word2vec embeddings. \n",
    "\n",
    "All of the packages utilized should be installed on your Azure servers, however you will have to download an NLTK corpus. To do this, follow the instructions below:\n",
    "\n",
    "1. SSH to your Azure server\n",
    "2. Open up Python interpreter\n",
    "3. `import nltk`\n",
    "4. `nltk.download()`\n",
    "\n",
    "    You should now see something that looks like:\n",
    "\n",
    "    ```\n",
    "    >>> nltk.download()\n",
    "    NLTK Downloader\n",
    "    ---------------------------------------------------------------------------\n",
    "        d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
    "    ---------------------------------------------------------------------------\n",
    "    Downloader> \n",
    "\n",
    "    ```\n",
    "\n",
    "5. `d punkt`\n",
    "6. Provided the download finished successfully, you may now exit out of the Python interpreter and close the SSH connection.\n",
    "\n",
    "Please look through the functions provided below **carefully**, as you will need to use all of them at some point in your assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = train_sentences\n",
    "\n",
    "# Lower-case the sentence, tokenize them and add <SOS> and <EOS> tokens\n",
    "sentences = [[\"<SOS>\"] + word_tokenize(sentence.lower()) + [\"<EOS>\"] for sentence in sentences]\n",
    "\n",
    "# Create the vocabulary. Note that we add an <UNK> token to represent words not in our vocabulary.\n",
    "vocabularySize = 1000\n",
    "word_counts = Counter([word for sentence in sentences for word in sentence])\n",
    "vocabulary = [\"<UNK>\"] + [e[0] for e in word_counts.most_common(vocabularySize-1)]\n",
    "word2index = {word:index for index,word in enumerate(vocabulary)}\n",
    "one_hot_embeddings = np.eye(vocabularySize)\n",
    "\n",
    "# Build the word2vec embeddings\n",
    "wordEncodingSize = 300\n",
    "filtered_sentences = [[word for word in sentence if word in word2index] for sentence in sentences]\n",
    "w2v = Word2Vec(filtered_sentences, min_count=0, size=wordEncodingSize)\n",
    "w2v_embeddings = np.concatenate((np.zeros((1, wordEncodingSize)), w2v.wv.syn0))\n",
    "\n",
    "# Define the max sequence length to be the longest sentence in the training data. \n",
    "maxSequenceLength = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "def preprocess_numberize(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into list of numbers (denoting the index into the vocabulary).\n",
    "    \"\"\"\n",
    "    tokenized = word_tokenize(sentence.lower())\n",
    "        \n",
    "    # Add the <SOS>/<EOS> tokens and numberize (all unknown words are represented as <UNK>).\n",
    "    tokenized = [\"<SOS>\"] + tokenized + [\"<EOS>\"]\n",
    "    numberized = [word2index.get(word, 0) for word in tokenized]\n",
    "    \n",
    "    return numberized\n",
    "\n",
    "def preprocess_one_hot(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of one-hot vectors.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    one_hot_embedded = one_hot_embeddings[numberized]\n",
    "    \n",
    "    return one_hot_embedded\n",
    "\n",
    "def preprocess_word2vec(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of word2vec embeddings.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    w2v_embedded = w2v_embeddings[numberized]\n",
    "    \n",
    "    return w2v_embedded\n",
    "\n",
    "def compute_bleu(reference_sentence, predicted_sentence):\n",
    "    \"\"\"\n",
    "    Given a reference sentence, and a predicted sentence, compute the BLEU similary between them.\n",
    "    \"\"\"\n",
    "    reference_tokenized = word_tokenize(reference_sentence.lower())\n",
    "    predicted_tokenized = word_tokenize(predicted_sentence.lower())\n",
    "    return sentence_bleu([reference_tokenized], predicted_tokenized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building a Language Decoder\n",
    "\n",
    "We now implement a language decoder. For now, we will have the decoder take a single training sample at a time (as opposed to batching). For our purposes, we will also avoid defining the embeddings as part of the model and instead pass in embedded inputs. While this is sometimes useful, as it learns/tunes the embeddings, we avoid doing it for the sake of simplicity and speed.\n",
    "\n",
    "Remember to use LSTM hidden units!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, isCuda):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = 300\n",
    "        \n",
    "        self.num_layers = 1\n",
    "        self.input_size = np.shape(w2v_embeddings)[1]\n",
    "        self.output_size = vocabularySize\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers)\n",
    "        self.linear = nn.Linear(hidden_size, self.output_size)\n",
    "        #self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.isCuda = isCuda\n",
    "\n",
    "    def forward(self, embedded_input, hx ,cx):\n",
    "        output, (hx, cx) = self.lstm(embedded_input,(hx, cx))\n",
    "        output = self.linear(output[0])\n",
    "        return output, hx, cx\n",
    "\n",
    "    def initHidden(self):\n",
    "        hx = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        cx = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        \n",
    "        return hx.cuda(),cx.cuda()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training a Language Decoder\n",
    "\n",
    "We must now train the language decoder we implemented above. An important thing to pay attention to is the [inputs for an LSTM](http://pytorch.org/docs/master/nn.html#torch.nn.LSTM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax()\n",
    "\n",
    "def train(sentence, \n",
    "          decoder, \n",
    "          decoder_optimizer, \n",
    "          criterion,\n",
    "          embeddings=w2v_embeddings): \n",
    "    \n",
    "    target_variable = preprocess_word2vec(sentence)\n",
    "    target_variable2 = word_tokenize(sentence.lower())\n",
    "\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    teacher_forcing_ratio = 0.5\n",
    "    \n",
    "    decoder_input = Variable(torch.FloatTensor(target_variable[1])).unsqueeze(0).unsqueeze(0)\n",
    "    decoder_input = decoder_input.cuda() \n",
    "    \n",
    "    decoder_optimizer.zero_grad()\n",
    "    hx,cx = decoder.initHidden()\n",
    "    \n",
    "    target_length = np.shape(target_variable)[0]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(2, target_length):\n",
    "            decoder_output, hx, cx = decoder(decoder_input, hx, cx)\n",
    "            #topv, topi = softmax(decoder_output).data.topk(1)\n",
    "            #ni = topi[0][0]\n",
    "            #print('predicted value: %s'%(vocabulary[ni]))\n",
    "            #decoder_input = Variable(torch.FloatTensor(np.eye(vocabularySize)[[ni]])).unsqueeze(0)\n",
    "            \n",
    "            decoder_input = Variable(torch.FloatTensor(target_variable[di])).unsqueeze(0).unsqueeze(0)\n",
    "            decoder_input = decoder_input.cuda() \n",
    "            \n",
    "            if (di != (target_length-1)):\n",
    "                    ti = word2index.get(target_variable2[di-1],0)\n",
    "            else:\n",
    "                    ti = word2index[\"<EOS>\"]\n",
    "                    \n",
    "            trueValue = Variable(torch.LongTensor(1))\n",
    "            trueValue.data[0] = ti\n",
    "            #print('true value: %s'%(vocabulary[trueWord]))\n",
    "\n",
    "            trueValue = trueValue.cuda() \n",
    " \n",
    "            loss += criterion(decoder_output, trueValue)\n",
    "            \n",
    "    else:\n",
    "        for di in range(2, target_length):\n",
    "\n",
    "                decoder_output, hx, cx = decoder(decoder_input, hx, cx)\n",
    "                topv, topi = softmax(decoder_output).data.topk(1)\n",
    "                ni = topi[0][0]\n",
    "                #print('predicted value: %s'%(vocabulary[ni]))\n",
    "\n",
    "                decoder_input = Variable(torch.FloatTensor(w2v_embeddings[[ni]])).unsqueeze(0)\n",
    "                decoder_input = decoder_input.cuda() \n",
    "\n",
    "                \n",
    "                if (di != (target_length-1)):\n",
    "                    ti = word2index.get(target_variable2[di-1],0)\n",
    "                else:\n",
    "                    ti = word2index[\"<EOS>\"]\n",
    "                    \n",
    "                trueValue = Variable(torch.LongTensor(1))\n",
    "                trueValue.data[0] = ti\n",
    "\n",
    "                trueValue = trueValue.cuda() \n",
    "\n",
    "                loss += criterion(decoder_output, trueValue)\n",
    "                if ni == word2index[\"<EOS>\"] :\n",
    "                    break\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def trainIters(decoder, n_iters, print_every=1000, plot_every=500, learning_rate=0.01):\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    optimizer = optim.Adam(decoder.parameters(),learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    #training_pairs = [variablesFromPair(random.choice(pairs))for i in range(n_iters)]\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        if(np.size(preprocess_numberize(train_sentences[iter-1]))>2): \n",
    "                \n",
    "            loss = train(train_sentences[iter-1], decoder, optimizer, criterion)\n",
    "\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('(%d %d%%) %.4f' % (iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            '''if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000 0%) 3.3667\n",
      "(2000 0%) 3.3648\n",
      "(3000 1%) 3.4044\n",
      "(4000 1%) 3.3877\n",
      "(5000 2%) 3.3873\n",
      "(6000 2%) 3.3066\n",
      "(7000 3%) 3.3172\n",
      "(8000 3%) 3.3110\n",
      "(9000 4%) 3.2074\n",
      "(10000 4%) 3.2956\n",
      "(11000 5%) 3.2625\n",
      "(12000 5%) 3.2573\n",
      "(13000 6%) 3.1770\n",
      "(14000 6%) 3.1486\n",
      "(15000 7%) 3.3253\n",
      "(16000 7%) 3.2798\n",
      "(17000 8%) 3.3501\n",
      "(18000 8%) 3.2866\n",
      "(19000 9%) 3.2907\n",
      "(20000 9%) 3.2381\n",
      "(21000 10%) 3.2682\n",
      "(22000 10%) 3.3218\n",
      "(23000 11%) 3.2938\n",
      "(25000 12%) 6.5249\n",
      "(26000 12%) 3.3910\n",
      "(27000 12%) 3.3370\n",
      "(28000 13%) 3.2200\n",
      "(29000 13%) 3.3154\n",
      "(30000 14%) 3.3127\n",
      "(31000 14%) 3.3945\n",
      "(32000 15%) 3.3787\n",
      "(33000 15%) 3.3552\n",
      "(34000 16%) 3.7236\n",
      "(35000 16%) 3.8140\n",
      "(36000 17%) 3.5887\n",
      "(37000 17%) 3.4109\n",
      "(38000 18%) 3.4786\n",
      "(39000 18%) 3.3816\n",
      "(40000 19%) 3.5108\n",
      "(41000 19%) 3.4438\n",
      "(42000 20%) 3.5171\n",
      "(43000 20%) 3.4081\n",
      "(44000 21%) 3.5175\n",
      "(45000 21%) 3.4784\n",
      "(46000 22%) 3.5536\n",
      "(47000 22%) 3.4538\n",
      "(48000 23%) 3.5859\n",
      "(49000 23%) 3.6646\n",
      "(50000 24%) 3.5939\n",
      "(51000 24%) 3.5293\n",
      "(52000 25%) 3.5226\n",
      "(53000 25%) 3.4092\n",
      "(54000 25%) 3.6979\n",
      "(55000 26%) 3.6117\n",
      "(56000 26%) 3.4764\n",
      "(57000 27%) 3.4779\n",
      "(58000 27%) 3.4059\n",
      "(59000 28%) 3.5472\n",
      "(60000 28%) 3.5536\n",
      "(61000 29%) 3.5754\n",
      "(62000 29%) 3.6288\n",
      "(63000 30%) 3.4930\n",
      "(64000 30%) 3.6304\n",
      "(65000 31%) 3.5376\n",
      "(66000 31%) 3.5156\n",
      "(67000 32%) 3.7069\n",
      "(68000 32%) 3.7700\n",
      "(69000 33%) 3.7237\n",
      "(70000 33%) 3.6237\n",
      "(71000 34%) 3.5076\n",
      "(72000 34%) 3.6527\n",
      "(73000 35%) 3.5495\n",
      "(74000 35%) 3.7685\n",
      "(75000 36%) 3.6013\n",
      "(76000 36%) 3.6635\n",
      "(77000 37%) 3.6506\n",
      "(78000 37%) 3.5280\n",
      "(79000 37%) 3.5792\n",
      "(80000 38%) 3.5404\n",
      "(81000 38%) 3.6487\n",
      "(82000 39%) 3.5727\n",
      "(83000 39%) 3.7274\n",
      "(84000 40%) 3.6062\n",
      "(85000 40%) 3.5393\n",
      "(86000 41%) 3.7252\n",
      "(87000 41%) 3.5875\n",
      "(88000 42%) 3.5841\n",
      "(89000 42%) 3.6266\n",
      "(90000 43%) 3.4960\n",
      "(91000 43%) 3.6072\n",
      "(92000 44%) 3.6283\n",
      "(93000 44%) 3.6450\n",
      "(94000 45%) 3.6346\n",
      "(95000 45%) 3.5925\n",
      "(96000 46%) 3.6271\n",
      "(97000 46%) 3.5754\n",
      "(98000 47%) 3.5664\n",
      "(99000 47%) 3.5117\n",
      "(100000 48%) 3.6967\n",
      "(101000 48%) 3.5219\n",
      "(102000 49%) 3.5382\n",
      "(103000 49%) 3.6434\n",
      "(104000 50%) 3.5550\n",
      "(105000 50%) 3.5821\n",
      "(106000 50%) 3.6608\n",
      "(107000 51%) 3.6581\n",
      "(108000 51%) 3.5744\n",
      "(109000 52%) 3.6998\n",
      "(110000 52%) 3.7261\n",
      "(111000 53%) 3.7317\n",
      "(112000 53%) 3.6495\n",
      "(113000 54%) 3.8110\n",
      "(114000 54%) 3.6951\n",
      "(115000 55%) 3.5631\n",
      "(116000 55%) 3.7198\n",
      "(117000 56%) 3.7003\n",
      "(118000 56%) 3.6885\n",
      "(119000 57%) 3.7341\n",
      "(120000 57%) 3.7342\n",
      "(121000 58%) 3.6430\n",
      "(122000 58%) 3.8914\n",
      "(123000 59%) 3.3760\n",
      "(124000 59%) 3.6044\n",
      "(125000 60%) 3.8744\n",
      "(126000 60%) 3.6496\n",
      "(127000 61%) 3.7034\n",
      "(128000 61%) 3.7170\n",
      "(129000 62%) 3.5608\n",
      "(130000 62%) 3.7801\n",
      "(131000 63%) 3.5161\n",
      "(132000 63%) 3.7888\n",
      "(133000 63%) 3.7602\n",
      "(134000 64%) 3.7866\n",
      "(135000 64%) 3.8401\n",
      "(136000 65%) 3.8695\n",
      "(137000 65%) 3.8811\n",
      "(138000 66%) 3.8251\n",
      "(139000 66%) 3.7150\n",
      "(140000 67%) 3.6670\n",
      "(141000 67%) 3.7744\n",
      "(142000 68%) 3.6987\n",
      "(143000 68%) 3.6754\n",
      "(144000 69%) 3.7830\n",
      "(145000 69%) 3.7553\n",
      "(146000 70%) 3.6305\n",
      "(147000 70%) 3.6997\n",
      "(148000 71%) 3.6787\n",
      "(149000 71%) 3.7657\n",
      "(150000 72%) 3.8504\n",
      "(151000 72%) 3.5206\n",
      "(152000 73%) 3.6964\n",
      "(153000 73%) 3.7839\n",
      "(154000 74%) 3.6294\n",
      "(155000 74%) 3.7788\n",
      "(156000 75%) 3.7525\n",
      "(157000 75%) 3.7182\n",
      "(158000 75%) 3.7618\n",
      "(159000 76%) 3.6239\n",
      "(160000 76%) 3.7489\n",
      "(161000 77%) 3.6737\n",
      "(162000 77%) 3.6165\n",
      "(163000 78%) 3.6976\n",
      "(164000 78%) 3.5048\n",
      "(165000 79%) 3.9816\n",
      "(166000 79%) 3.9887\n",
      "(167000 80%) 3.8880\n",
      "(168000 80%) 4.0568\n",
      "(169000 81%) 3.9147\n",
      "(170000 81%) 3.9545\n",
      "(171000 82%) 3.7481\n",
      "(172000 82%) 3.8702\n",
      "(173000 83%) 3.9656\n",
      "(174000 83%) 4.0176\n",
      "(175000 84%) 3.8863\n",
      "(176000 84%) 3.8502\n",
      "(177000 85%) 3.8503\n",
      "(178000 85%) 3.7817\n",
      "(179000 86%) 3.7569\n",
      "(180000 86%) 4.0105\n",
      "(181000 87%) 3.8505\n",
      "(182000 87%) 3.8223\n",
      "(183000 88%) 3.7724\n",
      "(184000 88%) 3.7323\n",
      "(185000 88%) 3.8207\n",
      "(186000 89%) 3.6777\n",
      "(187000 89%) 3.9186\n",
      "(188000 90%) 3.9145\n",
      "(189000 90%) 3.6773\n",
      "(190000 91%) 3.7573\n",
      "(191000 91%) 3.9741\n",
      "(192000 92%) 3.7607\n",
      "(193000 92%) 3.5794\n",
      "(194000 93%) 3.8413\n",
      "(195000 93%) 3.7360\n",
      "(196000 94%) 3.6553\n",
      "(197000 94%) 3.6850\n",
      "(198000 95%) 4.2448\n",
      "(199000 95%) 4.7737\n",
      "(200000 96%) 4.1167\n",
      "(201000 96%) 4.1565\n",
      "(202000 97%) 4.2040\n",
      "(203000 97%) 4.1371\n",
      "(204000 98%) 4.0739\n",
      "(205000 98%) 4.0864\n",
      "(206000 99%) 4.1107\n",
      "(207000 99%) 4.1363\n"
     ]
    }
   ],
   "source": [
    "isCuda = True\n",
    "hidden_size = 300\n",
    "decoder = DecoderLSTM(hidden_size, isCuda).cuda()\n",
    "size = math.floor(np.size(sentences)/2)\n",
    "trainIters(decoder,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building Language Decoder MAP Inference\n",
    "\n",
    "We now define a method to perform inference with our decoder and test it with a few different starting words. This code will be fairly similar to your training function from part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the man is white clouds <UNK> a man and a frisbee <UNK> a . \n",
      "man and a frisbee <UNK> a . \n",
      "woman is white clouds <UNK> a man and a frisbee <UNK> a . \n",
      "dog is white clouds <UNK> a man and a frisbee <UNK> a . \n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax()\n",
    "def inference(decoder, init_word, embeddings=w2v_embeddings, max_length = maxSequenceLength):\n",
    "    \n",
    "    decoder.eval()\n",
    "    \n",
    "    isCuda = True\n",
    "    \n",
    "    decoder_input = Variable(torch.FloatTensor(w2v_embeddings[[word2index.get(init_word, 0)]])).unsqueeze(0)\n",
    "    decoder_input = decoder_input.cuda() \n",
    "\n",
    "    hx,cx = decoder.initHidden()\n",
    "\n",
    "    result = init_word + \" \"\n",
    "    i = 0 \n",
    "    \n",
    "    while True:\n",
    "            i += 1\n",
    "            decoder_output, hx, cx = decoder(decoder_input, hx, cx)\n",
    "            topv, topi = softmax(decoder_output).data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            if ni == word2index[\"<EOS>\"] or i == max_length:\n",
    "                break\n",
    "            result = result + vocabulary[ni] + \" \"\n",
    "            decoder_input = Variable(torch.FloatTensor(w2v_embeddings[[ni]])).unsqueeze(0)\n",
    "            decoder_input = decoder_input.cuda() if isCuda else decoder_input\n",
    "            \n",
    "                      \n",
    "    return result\n",
    "\n",
    "print(inference(decoder, init_word=\"the\"))\n",
    "print(inference(decoder, init_word=\"man\"))\n",
    "print(inference(decoder, init_word=\"woman\"))\n",
    "print(inference(decoder, init_word=\"dog\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building Language Decoder Sampling Inference\n",
    "\n",
    "We must now modify the method defined in part 3, to sample from the distribution outputted by the LSTM rather than taking the most probable word.\n",
    "\n",
    "It might be useful to take a look at the output of your model and (depending on your implementation) modify it so that the outputs sum to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the brown horse next to to bat under a dog bed \n",
      "man holding a zoo enclosure with a frisbee <UNK> <UNK> . frisbee together in playing grazing on grass next to a rocky to bat under and a frisbee the same a tree . \n",
      "woman a dog <UNK> <UNK> to their hat his head the ocean with trees around a yellow chair . \n",
      "dog man drawn a person , and sliced eaten . \n"
     ]
    }
   ],
   "source": [
    "def sampling_inference(decoder, init_word, embeddings=w2v_embeddings, max_length=maxSequenceLength):\n",
    "    \n",
    "    decoder.eval()\n",
    "    \n",
    "    isCuda = True\n",
    "    \n",
    "    decoder_input = Variable(torch.FloatTensor(w2v_embeddings[[word2index.get(init_word, 0)]])).unsqueeze(0)\n",
    "    decoder_input = decoder_input.cuda()\n",
    "    hx,cx = decoder.initHidden()\n",
    "\n",
    "    result = init_word + \" \"\n",
    "    i = 0 \n",
    "    \n",
    "    while True:\n",
    "            i += 1\n",
    "            decoder_output, hx, cx = decoder(decoder_input, hx, cx)\n",
    "            probabilities = np.squeeze(np.transpose(softmax(decoder_output.cpu()).data.numpy()))\n",
    "            ni = np.random.choice(np.arange(0, 1000), p = probabilities)\n",
    "            if ni == word2index[\"<EOS>\"] or i == max_length:\n",
    "                break\n",
    "            result = result + vocabulary[ni] + \" \"\n",
    "            decoder_input = Variable(torch.FloatTensor(w2v_embeddings[[ni]])).unsqueeze(0)\n",
    "            decoder_input = decoder_input.cuda() if isCuda else decoder_input       \n",
    "                      \n",
    "    return result\n",
    "\n",
    "# Print the results with sampling_inference by drawing 5 samples per initial word, requiring to run \n",
    "# the code below 5 times\n",
    "print(sampling_inference(decoder, init_word=\"the\"))\n",
    "print(sampling_inference(decoder, init_word=\"man\"))\n",
    "print(sampling_inference(decoder, init_word=\"woman\"))\n",
    "print(sampling_inference(decoder, init_word=\"dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the young boy is white clouds showing `` topped with lots of a people in a . \n",
      "man grazing on grass \n",
      "woman on back topped with people in a stall field . \n",
      "dog sitting in an enclosure next to a and horses on grass <UNK> a large <UNK> this is a short park . \n",
      "\n",
      " ************** \n",
      "\n",
      "the playing in front of a . \n",
      "man is white photograph black a a a person a zebra dog 's <UNK> red and white photo on the beach . \n",
      "woman laying horses and clouds as she air . \n",
      "dog <UNK> people of dogs lying on back area \n",
      "\n",
      " ************** \n",
      "\n",
      "the three different colored on a a rock . \n",
      "man dog . preparing to catch a frisbee <UNK> two <UNK> hole a game with frisbee . from a . \n",
      "woman playing together in a rug grass field \n",
      "dog in a some <UNK> their and some horses running with two men in a street . in a grassy pasture . \n",
      "\n",
      " ************** \n",
      "\n",
      "the stand next a a brown frisbee \n",
      "man in brown <UNK> with several zebras \n",
      "woman is served . '' on the <UNK> counter . \n",
      "dog . horses are playing horses . a <UNK> suit posing \n",
      "\n",
      " ************** \n",
      "\n",
      "the horses walking looking into the <UNK> to <UNK> a picture of the standing in a red frisbee looking to bushes in the snow . \n",
      "man in a glass of wine catch food off of a tree . \n",
      "woman is frisbee grazing in through grass \n",
      "dog standing in together in a frisbee . \n",
      "\n",
      " ************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(sampling_inference(decoder, init_word=\"the\"))\n",
    "    print(sampling_inference(decoder, init_word=\"man\"))\n",
    "    print(sampling_inference(decoder, init_word=\"woman\"))\n",
    "    print(sampling_inference(decoder, init_word=\"dog\"))\n",
    "    print(\"\\n ************** \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  Building Language Encoder\n",
    "\n",
    "We now build a language encoder, which will encode an input word by word, and ultimately output a hidden state that we can then be used by our decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, isCuda):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.isCuda = isCuda\n",
    "\n",
    "        self.num_layers = 1\n",
    "        self.input_size = np.shape(w2v_embeddings)[1]\n",
    "        #self.output_size = vocabularySize\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers)\n",
    "        #self.linear = nn.Linear(hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, embedded_input, hx ,cx):\n",
    "        output, (hx, cx) = self.lstm(embedded_input,(hx, cx))\n",
    "        #output = self.linear(output[0])\n",
    "        return output, hx, cx\n",
    "\n",
    "    def initHidden(self):\n",
    "        hx = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        cx = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        if isCuda:\n",
    "            return hx.cuda(),cx.cuda()\n",
    "        else:\n",
    "            return hx,cx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Connecting Encoder to Decoder and Training End-to-End\n",
    "\n",
    "We now connect our newly created encoder with our decoder, to train an end-to-end seq2seq architecture. \n",
    "\n",
    "It's likely that you'll be able to re-use most of your code from part 2. For our purposes, the only interaction between the encoder and the decoder is that the *last hidden state of the encoder is used as the initial hidden state of the decoder*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(sentence, \n",
    "          encoder,\n",
    "          encoder_optimizer,\n",
    "          decoder, \n",
    "          decoder_optimizer, \n",
    "          criterion,\n",
    "          embeddings=w2v_embeddings): \n",
    "    \n",
    "    target_variable = preprocess_word2vec(sentence)\n",
    "    target_variable2 = word_tokenize(sentence.lower())\n",
    "\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    isCuda = True\n",
    "    target_length = np.shape(target_variable)[0]\n",
    "\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    hx,cx = encoder.initHidden()\n",
    "    for ei in range(0,target_length):\n",
    "        encoder_input = Variable(torch.FloatTensor(target_variable[ei])).unsqueeze(0).unsqueeze(0)\n",
    "        encoder_input = encoder_input.cuda()\n",
    "        encoder_output, hx, cx = encoder(encoder_input, hx, cx)    \n",
    "    \n",
    "    decoder_input = Variable(torch.FloatTensor(target_variable[0])).unsqueeze(0).unsqueeze(0)\n",
    "    decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    loss = 0\n",
    "    for di in range(2, target_length):\n",
    "            \n",
    "            decoder_output, hx, cx = decoder(decoder_input, hx, cx)\n",
    "            topv, topi = softmax(decoder_output).data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            #print('predicted value: %s'%(vocabulary[ni]))\n",
    "            \n",
    "            decoder_input = Variable(torch.FloatTensor(w2v_embeddings[[ni]])).unsqueeze(0)\n",
    "            decoder_input = decoder_input.cuda() if isCuda else decoder_input\n",
    "            if (di != (target_length-1)):\n",
    "                ti = word2index.get(target_variable2[di-1],0)\n",
    "            else:\n",
    "                ti = word2index[\"<EOS>\"]\n",
    "                    \n",
    "            trueValue = Variable(torch.LongTensor(1))\n",
    "            trueValue.data[0] = ti\n",
    "            trueValue = trueValue.cuda() \n",
    "            loss += criterion(decoder_output, trueValue)\n",
    "            if ni == word2index[\"<EOS>\"] :\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=500, learning_rate=0.01):\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    isCuda= True\n",
    "    learning_rate=0.01\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(),learning_rate)\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(),learning_rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    #training_pairs = [variablesFromPair(random.choice(pairs))for i in range(n_iters)]\n",
    "\n",
    "    for iter in range(1, n_iters+1):\n",
    "        if(np.size(preprocess_numberize(train_sentences[iter-1]))>2): \n",
    "                \n",
    "\n",
    "            loss = train(train_sentences[iter-1], encoder, encoder_optimizer, decoder, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('(%d %d%%) %.4f' % (iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000 0%) 3.4012\n",
      "(2000 1%) 3.3075\n",
      "(3000 2%) 3.4080\n",
      "(4000 3%) 3.2311\n",
      "(5000 4%) 3.3215\n",
      "(6000 5%) 3.3710\n",
      "(7000 6%) 3.3383\n",
      "(8000 7%) 2.9751\n",
      "(9000 8%) 3.2291\n",
      "(10000 9%) 3.4056\n",
      "(11000 10%) 3.2156\n",
      "(12000 11%) 3.2290\n",
      "(13000 12%) 3.2564\n",
      "(14000 13%) 3.2803\n",
      "(15000 14%) 3.4824\n",
      "(16000 15%) 3.3378\n",
      "(17000 16%) 3.3116\n",
      "(18000 17%) 3.4178\n",
      "(19000 18%) 3.1997\n",
      "(20000 19%) 3.3462\n",
      "(21000 20%) 3.3656\n",
      "(22000 21%) 3.1741\n",
      "(23000 22%) 3.3956\n",
      "(25000 24%) 6.5449\n",
      "(26000 25%) 3.3148\n",
      "(27000 25%) 3.2540\n",
      "(28000 26%) 3.3362\n",
      "(29000 27%) 3.4114\n",
      "(30000 28%) 3.4567\n",
      "(31000 29%) 3.3378\n",
      "(32000 30%) 3.2783\n",
      "(33000 31%) 3.3807\n",
      "(34000 32%) 3.7689\n",
      "(35000 33%) 3.6520\n",
      "(36000 34%) 3.5407\n",
      "(37000 35%) 3.4346\n",
      "(38000 36%) 3.7283\n",
      "(39000 37%) 3.5816\n",
      "(40000 38%) 3.7096\n",
      "(41000 39%) 3.6674\n",
      "(42000 40%) 3.5629\n",
      "(43000 41%) 3.6084\n",
      "(44000 42%) 3.7970\n",
      "(45000 43%) 3.7142\n",
      "(46000 44%) 3.6690\n",
      "(47000 45%) 3.5484\n",
      "(48000 46%) 3.5976\n",
      "(49000 47%) 3.6336\n",
      "(50000 48%) 3.5839\n",
      "(51000 49%) 3.6670\n",
      "(52000 50%) 3.5234\n",
      "(53000 50%) 3.4926\n",
      "(54000 51%) 3.5647\n",
      "(55000 52%) 3.5258\n",
      "(56000 53%) 3.4902\n",
      "(57000 54%) 3.4928\n",
      "(58000 55%) 3.2944\n",
      "(59000 56%) 3.4169\n",
      "(60000 57%) 3.5427\n",
      "(61000 58%) 3.5482\n",
      "(62000 59%) 3.6679\n",
      "(63000 60%) 3.7433\n",
      "(64000 61%) 3.5708\n",
      "(65000 62%) 3.4831\n",
      "(66000 63%) 3.6011\n",
      "(67000 64%) 4.0630\n",
      "(68000 65%) 3.9216\n",
      "(69000 66%) 3.8590\n",
      "(70000 67%) 3.7978\n",
      "(71000 68%) 3.7416\n",
      "(72000 69%) 3.9025\n",
      "(73000 70%) 3.6343\n",
      "(74000 71%) 3.8724\n",
      "(75000 72%) 3.6850\n",
      "(76000 73%) 3.6649\n",
      "(77000 74%) 3.7683\n",
      "(78000 75%) 3.7469\n",
      "(79000 75%) 3.5755\n",
      "(80000 76%) 3.7771\n",
      "(81000 77%) 3.6620\n",
      "(82000 78%) 3.4680\n",
      "(83000 79%) 3.4980\n",
      "(84000 80%) 3.6823\n",
      "(85000 81%) 3.5733\n",
      "(86000 82%) 3.6710\n",
      "(87000 83%) 3.7413\n",
      "(88000 84%) 3.5545\n",
      "(89000 85%) 3.7216\n",
      "(90000 86%) 3.5818\n",
      "(91000 87%) 3.6533\n",
      "(92000 88%) 3.6603\n",
      "(93000 89%) 3.5262\n",
      "(94000 90%) 3.6172\n",
      "(95000 91%) 3.5791\n",
      "(96000 92%) 3.6920\n",
      "(97000 93%) 3.6726\n",
      "(98000 94%) 3.5807\n",
      "(99000 95%) 3.6749\n",
      "(100000 96%) 3.8024\n",
      "(101000 97%) 3.8008\n",
      "(102000 98%) 3.8360\n",
      "(103000 99%) 3.7704\n"
     ]
    }
   ],
   "source": [
    "isCuda = True\n",
    "hidden_size = 300\n",
    "decoder = DecoderLSTM(hidden_size, isCuda).cuda()\n",
    "encoder = EncoderLSTM(hidden_size, isCuda).cuda()\n",
    "\n",
    "size = math.floor(np.size(sentences)/4)\n",
    "trainIters(encoder, decoder, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Testing \n",
    "\n",
    "We must now define a method that allows us to do inference using the seq2seq architecture. We then run the 500 validation captions through this method, and ultimately compare the **reference** and **generated** sentences using our **BLEU** similarity score method defined above, to identify the average BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax()\n",
    "\n",
    "def seq2seq_inference(sentence, encoder, decoder, embeddings=w2v_embeddings, max_length = maxSequenceLength):\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    isCuda = True\n",
    "    \n",
    "    hx,cx = encoder.initHidden()\n",
    "    target_variable = preprocess_word2vec(sentence) \n",
    "    sentence_length = np.shape(target_variable)[0]\n",
    "\n",
    "\n",
    "\n",
    "    for ei in range(0,sentence_length):\n",
    "        encoder_input = Variable(torch.FloatTensor(target_variable[ei])).unsqueeze(0).unsqueeze(0)\n",
    "        encoder_input = encoder_input.cuda()\n",
    "        encoder_output, hx, cx = encoder(encoder_input, hx, cx)\n",
    "\n",
    "    decoder_input = Variable(torch.FloatTensor(target_variable[0])).unsqueeze(0).unsqueeze(0)\n",
    "    decoder_input = decoder_input.cuda()\n",
    "\n",
    "    predicted_sentence = word_tokenize(sentence)[0]+\" \"\n",
    "    i = 0 \n",
    "    \n",
    "    while True:\n",
    "            i += 1\n",
    "            decoder_output, hx, cx = decoder(decoder_input, hx, cx)\n",
    "            topv, topi = softmax(decoder_output).data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            if ni == word2index[\"<EOS>\"] or i == max_length:\n",
    "                break\n",
    "            predicted_sentence = predicted_sentence + vocabulary[ni] + \" \"\n",
    "            decoder_input = Variable(torch.FloatTensor(w2v_embeddings[[ni]])).unsqueeze(0)\n",
    "            decoder_input = decoder_input.cuda() if isCuda else decoder_input\n",
    "            \n",
    "    return predicted_sentence, compute_bleu(sentence, predicted_sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43043897164777595\n"
     ]
    }
   ],
   "source": [
    "# Perform inference for all validation sequences and report the average BLEU score\n",
    "total = 0\n",
    "\n",
    "for i,val_sentence in enumerate(val_sentences):\n",
    "    predicted_sentence, similarity = seq2seq_inference(val_sentence, encoder, decoder)\n",
    "    total += similarity\n",
    "\n",
    "avg = total/len(val_sentences)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Encoding as Generic Feature Representation\n",
    "\n",
    "We now use the final hidden state of our encoder, to identify the nearest neighbor amongst the training sentences for each sentence in our validation data.\n",
    "\n",
    "It would be effective to first define a method that would generate all of the hidden states and store these hidden states **on the CPU**, and then loop over the generated hidden states to identify/output the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_encoder_hidden(sentence):\n",
    "    \n",
    "    target_variable = preprocess_word2vec(sentence) \n",
    "    sentence_length = np.shape(target_variable)[0]\n",
    "    hx,cx = encoder.initHidden()\n",
    "    for ei in range(0,sentence_length):\n",
    "        encoder_input = Variable(torch.FloatTensor(target_variable[ei])).unsqueeze(0).unsqueeze(0)\n",
    "        encoder_input = encoder_input.cuda()\n",
    "        encoder_output, hx, cx = encoder(encoder_input, hx, cx)\n",
    "    return hx.data[0][0].cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now run all training data and validation data to store hidden states\n",
    "size = math.floor(np.size(sentences)/4)\n",
    "hx_store = np.zeros((size,hidden_size))\n",
    "for i,train_sentence in enumerate(train_sentences[0:size]):\n",
    "    hx_store[i] = final_encoder_hidden(train_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_sentence: A man and woman at a table with beer and wine \n",
      "close_sentence: A man stands near a very large selection of fruits and vegetables \n",
      "\n",
      "val_sentence: A man speaking into a microphone on a stage with a bicycle and dressed in cyclist gear. \n",
      "close_sentence: A man in a room with a LCD television showing a movie. \n",
      "\n",
      "val_sentence: Four horses are skattered around a small water hole. \n",
      "close_sentence: A bathroom divided with the tub and toilet in one partition and the sink in the other half of the room. \n",
      "\n",
      "val_sentence: A man and a young girl playing Wii \n",
      "close_sentence: A little girl is reading a book in the living room. \n",
      "\n",
      "val_sentence: A boat home sitting on a river bay. \n",
      "close_sentence: A white police vehicle parked in a parking lot. \n",
      "\n",
      "val_sentence: Several Tim's of mints are stacked up with a bottle that has several  clipped roses inside \n",
      "close_sentence: an airplane hanging down from the cieling inside \n",
      "\n",
      "val_sentence: Family at a pizza restaurant posing for a picture before meal. \n",
      "close_sentence: A view through a bathroom doorway without a doorway, showing turquoise tile and an unfinished wall section. \n",
      "\n",
      "val_sentence: Several mopeds are lined up along the side of a hotel parking lot. \n",
      "close_sentence: Two city buses parked in an empty parking lot. \n",
      "\n",
      "val_sentence: A young man appears to be taking a break from the waves. \n",
      "close_sentence: The chef is standing over a grill as flames jump from the food. \n",
      "\n",
      "val_sentence: A baseball player standing next to home plate with a bat. \n",
      "close_sentence: A plane has just taken off in late afternoon. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now get nearest neighbors and print\n",
    "size = math.floor(np.size(sentences)/4)\n",
    "\n",
    "for val_sentence in val_sentences[:10]:\n",
    "    hx_val = final_encoder_hidden(val_sentence)\n",
    "    min_dist = math.inf\n",
    "    neighbor_index = 0\n",
    "    for i,train_sentence in enumerate(train_sentences[0:size]):\n",
    "        dist = np.linalg.norm(hx_val-hx_store[i])\n",
    "        if(dist < min_dist):\n",
    "            closest_sentence = train_sentence\n",
    "            min_dist = dist \n",
    "            \n",
    "    print('val_sentence: %s '% val_sentence)\n",
    "    print('close_sentence: %s \\n'% closest_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
